# Reporting Guide

This document describes the structure, location, and interpretation of reports generated by the EddyPro Batch Processor.

## Overview

The batch processor generates comprehensive reports for each run, including:

- Run manifests (machine-readable JSON)
- HTML reports with interactive visualizations
- Per-scenario metrics and metadata
- Performance time series data

## Report Location

### Default Location

Reports are stored in a `reports/` subdirectory within the output directory:

```
{output_dir_pattern}/{site_id}/{year}/reports/
```

**Example:**
```
D:/L1_processed/GL-ZaF/2021/ec_rflux/reports/
```

### Custom Location

Override the default location:

**Via config:**
```yaml
reports_dir: "D:/custom/reports"
```

**Via CLI:**
```bash
eddypro-batch run --reports-dir /custom/reports
```

---

## Report Files

### run_manifest.json

**Purpose:** Machine-readable summary of the entire run

**Location:** `{reports_dir}/run_manifest.json`

**Schema:**

```json
{
  "run_id": "20251002_100530",
  "config_hash": "a1b2c3d4",
  "git_sha": "1234567890abcdef",
  "start_time": "2025-10-02T10:05:30",
  "end_time": "2025-10-02T11:20:15",
  "duration_seconds": 4485.2,
  "site_id": "GL-ZaF",
  "years": [2021, 2022],
  "scenarios": [
    {
      "scenario_id": "rot1_tlag2",
      "parameters": {"rot_meth": 1, "tlag_meth": 2},
      "success": true,
      "duration_seconds": 932.1,
      "output_dir": "/path/to/_rot1_tlag2",
      "metrics_summary": {
        "cpu_percent_avg": 45.2,
        "memory_rss_peak_mb": 1024.5
      }
    }
  ],
  "summary": {
    "total_scenarios": 4,
    "successful": 4,
    "failed": 0
  },
  "environment": {
    "python_version": "3.12.6",
    "eddypro_version": "7.0.9",
    "packages": {
      "psutil": "5.9.0",
      "plotly": "5.14.0"
    }
  }
}
```

---

### run_report.html

**Purpose:** Human-readable report with visualizations

**Location:** `{reports_dir}/run_report.html`

**Contents:**

1. **Run Summary**
   - Run ID, timestamps, duration
   - Configuration snapshot
   - Success/failure counts

2. **Scenario Matrix**
   - Table of all scenarios with parameters
   - Status indicators (✓/✗)
   - Per-scenario timings

3. **Performance Charts**
   - CPU usage over time (all scenarios)
   - Memory usage over time
   - Disk I/O throughput
   - Scenario comparison bar charts

4. **Metrics Table**
   - Min/avg/max CPU, memory, I/O per scenario
   - Duration comparison
   - Sorting and filtering controls

5. **Environment & Provenance**
   - Software versions
   - Config checksums
   - Git commit SHA (if available)

**Chart Engine:**
- Default: Plotly (interactive, zoomable, exportable)
- Fallback: SVG (static images)
- Override: `--report-charts svg` or `--report-charts none`

---

### Per-Scenario Artifacts

Each scenario produces additional files in its output directory:

#### manifest.json

**Location:** `{output_dir}/{scenario_suffix}/manifest.json`

**Example:**
```
D:/L1_processed/GL-ZaF/2021/ec_rflux/_rot1_tlag2/manifest.json
```

**Schema:**

```json
{
  "scenario_id": "rot1_tlag2",
  "parameters": {
    "rot_meth": 1,
    "tlag_meth": 2
  },
  "project_file": "/path/to/GL-ZaF_2021_rot1_tlag2.eddypro",
  "output_dir": "/path/to/_rot1_tlag2",
  "timestamps": {
    "start": "2025-10-02T10:00:00",
    "end": "2025-10-02T10:15:32"
  },
  "success": true,
  "exit_code": 0,
  "eddypro_log": "/path/to/eddypro_processing.log",
  "metrics": {
    "duration_seconds": 932.1,
    "cpu_percent_min": 12.3,
    "cpu_percent_avg": 45.2,
    "cpu_percent_max": 89.4,
    "memory_rss_peak_mb": 1024.5,
    "memory_rss_avg_mb": 512.3,
    "disk_read_mb": 512.3,
    "disk_write_mb": 128.7,
    "disk_read_iops": 1234,
    "disk_write_iops": 456
  },
  "output_files": [
    "eddypro_full_output_2021.csv",
    "eddypro_metadata_2021.txt",
    "eddypro_qc_details_2021.txt"
  ]
}
```

#### metrics.csv

**Location:** `{output_dir}/{scenario_suffix}/metrics.csv`

**Purpose:** Performance time series sampled during EddyPro execution

**Schema:**

```csv
timestamp,elapsed_seconds,cpu_percent_process,cpu_percent_system,memory_rss_mb,memory_vms_mb,disk_read_mb,disk_write_mb,disk_read_iops,disk_write_iops
2025-10-02T10:00:00,0.0,5.2,15.3,128.5,256.0,0.0,0.0,0,0
2025-10-02T10:00:00.5,0.5,42.1,58.7,512.3,1024.0,10.5,2.3,120,45
2025-10-02T10:00:01.0,1.0,55.8,72.1,768.9,1536.0,15.2,3.8,180,67
...
```

**Columns:**
- `timestamp`: ISO 8601 timestamp
- `elapsed_seconds`: time since scenario start
- `cpu_percent_process`: CPU usage of EddyPro process
- `cpu_percent_system`: system-wide CPU usage
- `memory_rss_mb`: resident set size (physical memory)
- `memory_vms_mb`: virtual memory size
- `disk_read_mb`: cumulative disk read in MB
- `disk_write_mb`: cumulative disk write in MB
- `disk_read_iops`: disk read operations per second
- `disk_write_iops`: disk write operations per second

---

## Interpreting Reports

### Run Summary

**Key Metrics:**

- **Duration**: Total wall-clock time for all scenarios
- **Success Rate**: `successful / total_scenarios`
- **Throughput**: Scenarios processed per hour

**Example:**
```
Run Duration: 1h 14m 45s
Scenarios: 4 total, 4 successful, 0 failed
Throughput: 3.2 scenarios/hour
```

### Scenario Comparison

**Useful for:**
- Identifying slowest/fastest parameter combinations
- Detecting memory or I/O bottlenecks
- Comparing resource usage across methods

**Look for:**
- Significantly longer durations (>2× median)
- High peak memory usage (risk of OOM)
- Low CPU usage (I/O bound or throttled)

### Performance Charts

#### CPU Usage

**Interpretation:**
- **High avg (>80%)**: CPU-bound, good utilization
- **Low avg (<30%)**: I/O-bound or waiting on disk/network
- **Spiky**: intermittent processing phases

**Actions:**
- High CPU: consider reducing `--max-proc` if oversubscribed
- Low CPU: check disk/network throughput, investigate I/O bottlenecks

#### Memory Usage

**Interpretation:**
- **Steady increase**: potential memory leak
- **Spikes at intervals**: batch processing phases (expected)
- **Near system limit**: risk of swapping or OOM

**Actions:**
- High memory: reduce scenario concurrency, increase RAM, investigate data loading

#### Disk I/O

**Interpretation:**
- **High read throughput**: reading large raw files (expected)
- **High write throughput**: writing outputs (expected)
- **Low throughput with high CPU wait**: disk bottleneck

**Actions:**
- Disk bottleneck: use faster storage (SSD/NVMe), reduce concurrent scenarios

---

## Provenance & Reproducibility

### Config Hash

**Purpose:** Unique identifier for configuration state

**Generation:** SHA256 hash of config file content (excluding comments/whitespace)

**Use:**
- Compare runs to detect config changes
- Link outputs to exact configuration used

### Git SHA

**Purpose:** Link reports to source code version

**Captured:** Git commit hash at runtime (if repository available)

**Use:**
- Reproduce results with specific code version
- Track code changes between runs

### Environment Snapshot

**Captured:**
- Python version
- Package versions (psutil, plotly, yaml, etc.)
- EddyPro version (if detectable)

**Use:**
- Reproduce results with identical environment
- Diagnose version-specific issues

---

## Exporting & Archiving

### JSON Exports

Machine-readable manifests can be:
- Ingested by downstream analysis tools
- Archived in databases
- Compared programmatically across runs

**Example workflow:**
```bash
# Extract scenario durations from manifest
jq '.scenarios[] | {id: .scenario_id, duration: .duration_seconds}' run_manifest.json
```

### HTML Reports

- Self-contained (embedded CSS/JS)
- Portable (share via email, intranet)
- Printable (with charts)

**Archiving:**
```bash
# Archive reports with timestamp
tar -czf reports_GL-ZaF_2021_$(date +%Y%m%d).tar.gz reports/
```

---

## Customizing Reports

### Chart Engine

**Plotly (default):**
- Interactive (zoom, pan, hover tooltips)
- Export to PNG/SVG/PDF
- Requires `plotly` package

**SVG:**
- Static images
- Lightweight
- No dependencies

**None:**
- Text and tables only
- Fastest generation
- Minimal file size

**Select:**
```bash
eddypro-batch run --report-charts svg
```

### Metrics Sampling Interval

**Higher resolution (more detail):**
```bash
eddypro-batch run --metrics-interval 0.1  # Sample every 100ms
```

**Lower resolution (less overhead):**
```bash
eddypro-batch run --metrics-interval 2.0  # Sample every 2 seconds
```

**Trade-offs:**
- Lower interval: more data, higher overhead, larger files
- Higher interval: less data, lower overhead, smaller files

---

## Troubleshooting

### Missing Reports

**Symptom:** Reports directory empty after run

**Possible Causes:**
- Run failed before report generation
- Insufficient disk space
- Permission issues

**Solutions:**
- Check logs for errors
- Verify `reports_dir` permissions
- Ensure adequate disk space

### Broken Charts

**Symptom:** HTML report displays chart placeholders or errors

**Possible Causes:**
- Plotly not installed
- Incompatible Plotly version
- Browser JavaScript disabled

**Solutions:**
- Install Plotly: `pip install plotly`
- Use SVG fallback: `--report-charts svg`
- Update browser or enable JavaScript

### Large Metrics Files

**Symptom:** `metrics.csv` files are very large

**Cause:** High sampling frequency and long scenario durations

**Solutions:**
- Increase `--metrics-interval` (e.g., from 0.5 to 1.0 or 2.0)
- Compress old metrics files: `gzip metrics.csv`
- Implement metrics retention policy (delete after N days)

---

## See Also

- [USAGE.md](USAGE.md) – CLI usage and examples
- [SCENARIOS.md](SCENARIOS.md) – Scenario matrix runs
- [CONFIG.md](CONFIG.md) – Configuration options
